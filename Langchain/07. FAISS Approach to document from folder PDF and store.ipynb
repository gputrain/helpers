{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42079ca5",
   "metadata": {},
   "source": [
    "##### A. Load OpenAI and other environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61e90a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14180d0",
   "metadata": {},
   "source": [
    "##### B. All my imports to read, embed and do a similarity search with score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a4d7e",
   "metadata": {},
   "source": [
    "##### https://python.langchain.com/docs/integrations/vectorstores/faiss reference for imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb156481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f46f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('data/Causal_Inference_in_Python.pdf')  #Loads a single PDF 400 page book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d60bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3fd6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 399)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pages), len(pages)  #Splits by PDF page approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071c4f0",
   "metadata": {},
   "source": [
    "##### C. Setup OpenAI embeddings to process the PDF doc in chunks and save / reload the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3377a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69713976",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(pages, embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "623ab3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"data/FAISS/faiss_index\")  #Save this embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7896b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db =  FAISS.load_local(\"data/FAISS/faiss_index\", embeddings_model)  #Reload from storage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d541b4b",
   "metadata": {},
   "source": [
    "##### D. Perform a similarity search with FAISS - note the score added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73098c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what does simplify dif-in-diff covariates with OLS mean?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1635e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search_with_score(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c76bfdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c98ef0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: CHAPTER 4\n",
      "The Unreasonable Effectiveness\n",
      "of Linear Regression\n",
      "In this chapter you’ll add  the first major debiasing technique in your causal inference\n",
      "arsenal: linear regression or ordinary least squares (OLS) and orthogonalization.\n",
      "Y ou’ll see how linear regression can adjust for confounders when estimating the rela‐\n",
      "tionship between a treatment and an outcome. But, more than that, I hope to equip\n",
      "you with the powerful concept of treatment orthogonalization. This idea, born in lin‐\n",
      "ear regression, will come in handy later on when you start to use machine learning\n",
      "models for causal inference.\n",
      "All You Need Is Linear Regression\n",
      "Before you skip to the next chapter because “oh, regression is so easy! It’s the first\n",
      "model I learned as a data scientist” and yada yada, let me assure you that no, you\n",
      "actually don’t know linear regression. In fact, regression is one of the most fascinat‐\n",
      "ing, powerful, and dangerous models in causal inference. Sure, it’s more than one\n",
      "hundred years old. But, to this day, it frequently catches even the best causal inference\n",
      "researchers off guard.\n",
      "OLS Research\n",
      "Don’t believe me? Just take a look at some recently published\n",
      "papers on the topic and you’ll see. A good place to start is the arti‐\n",
      "cle “Difference-in-Differences with Variation in Treatment Tim‐\n",
      "ing, ” by Andrew Goodman-Bacon, or the paper “Interpreting OLS\n",
      "Estimands When Treatment Effects Are Heterogeneous” by Tymon\n",
      "Słoczyński, or even the paper “Contamination Bias in Linear\n",
      "Regressions” by Goldsmith-Pinkham et al.95, Metadata: {'source': 'data/Causal_Inference_in_Python.pdf', 'page': 116}, Score: 0.3759317994117737\n",
      "Content: Alternative Coefficient  Formula\n",
      "The fact that you only need to residualize the treatment suggests a simpler way of\n",
      "rewriting the regression coefficient formula. In the single variable case, instead of\n",
      "using the covariance of Y and T over the variance of T, you can useβ1=ETi−Tyi\n",
      "ETi−T2.\n",
      "In the multivariate case, this would beβ1=ETi−ETXyi\n",
      "EVar TX.\n",
      "There is a difference, though. Look at the p-value. It is a bit higher than what you got\n",
      "earlier. That’s because you are not applying the denoising step, which is responsible\n",
      "for reducing variance. Still, with only the debiasing step, you can already get the\n",
      "unbiased estimate of the causal impact of credit limit on risk, given that all the con‐\n",
      "founders were included in the debiasing model.\n",
      "Y ou can also visualize what is going on by plotting the debiased version of credit limit\n",
      "against default rate. Y ou’ll see that the relationship is no longer downward sloping, as\n",
      "when the data was biased:\n",
      "Denoising Step\n",
      "While the debiasing step is crucial to estimate the correct causal effect, the denoising\n",
      "step is also nice to have, although not as important. It won’t change the value of your\n",
      "treatment effect estimate, but it will reduce its variance. In this step, you’ll regress theFrisch-Waugh-Lovell Theorem and Orthogonalization | 109, Metadata: {'source': 'data/Causal_Inference_in_Python.pdf', 'page': 130}, Score: 0.38252586126327515\n",
      "Content: If you have more than one regressor, you can extend the one variable regression for‐\n",
      "mula to accommodate that. Let’s say those other variables are just auxiliary and that\n",
      "you are truly interested in estimating the parameter τ associated to T:yi=β0+τTi+β1X1i+ . . . + βkXki+uiτ can be estimated with the following formula:τ=Cov Yi,Ti\n",
      "Var Ti\n",
      "where Ti is the residual from a regression of Ti on all of the other covariatesX1i+ . . . + Xki\n",
      ".\n",
      "Now, let’s appreciate how cool this is. It means that the coefficient of a multivariate\n",
      "regression is the bivariate coefficient of the same regressor after  accounting for the\n",
      "effect  of other variables in the model . In causal inference terms, τ is the bivariate coeffi‐\n",
      "cient of T after having used all other variables to predict it.\n",
      "This has a nice intuition behind it. If you can predict T using other variables, it\n",
      "means it’s not random. However, you can make T look as good as random once you\n",
      "control for the all the confounder variables X. To do so, you can use linear regression\n",
      "to predict it from the confounder and then take the residuals of that regression T. By\n",
      "definition, T cannot be predicted by the other variables X that you’ve already used to\n",
      "predict T. Quite elegantly, T is a version of the treatment that is not associated\n",
      "(uncorrelated) with any other variable in X.\n",
      "I know this is a mouthful, but it is just amazing. In fact, it is already the work of the\n",
      "FWL theorem that I promised to teach you. So don’t worry if you didn’t quite get this\n",
      "multivariate regression part, as you are about to review it in a much more intuitive\n",
      "and visual way.\n",
      "Frisch-Waugh-Lovell Theorem and Orthogonalization\n",
      "FWL-style orthogonalization is the first major debiasing technique you have at your\n",
      "disposal . It’s a simple yet powerful way to make nonexperimental data look as if the\n",
      "treatment has been randomized. FWL is mostly about linear regression; FWL-style\n",
      "orthogonalization has been expanded to work in more general contexts, as you’ll see\n",
      "in Part III . The Frisch-Waugh-Lovell theorem states that a multivariate linear regres‐\n",
      "sion model can be estimated all at once or in three separate steps. For example, you\n",
      "can regress default  on credit_limit , wage , credit_score1 , credit_score2 , just\n",
      "like you already did:106 | Chapter 4: The Unreasonable Effectiveness  of Linear Regression, Metadata: {'source': 'data/Causal_Inference_in_Python.pdf', 'page': 127}, Score: 0.38532882928848267\n",
      "Content: to primarily adjust for confounders and, sometimes, as a variance reduction\n",
      "technique.\n",
      "The core of this chapter was orthogonalization as a means to make treatment look as\n",
      "good as randomly assigned if conditional independence holds. Formally, if Yt⊥TX\n",
      ",\n",
      "you can adjust for the confounding bias due to X by regressing T on X and obtaining\n",
      "the residuals. Those residuals can be seen as a debiased version of the treatment.\n",
      "This approach was further developed using the Frisch-Waugh-Lovell theorem, which\n",
      "states that a multivariate regression can be decomposed into the following steps:1.\n",
      "A debiasing step, where you regress the treatment T on confounders X and\n",
      "obtain the treatment residuals T=T−T 2.\n",
      "A denoising step, where you regress the outcome Y on the confounder variablesX and obtain the outcome residuals Y=Y−Y 3.\n",
      "An outcome model where you regress the outcome residual Y on the treatment\n",
      "residual T to obtain an estimate for the causal effect of T on YEverything else in the chapter follows from this theorem—be it nonlinear treatment\n",
      "response functions, understanding how regression with categorical variables imple‐\n",
      "ments a weighted average, or the role of good and bad controls in regression.140 | Chapter 4: The Unreasonable Effectiveness  of Linear Regression, Metadata: {'source': 'data/Causal_Inference_in_Python.pdf', 'page': 161}, Score: 0.3889247179031372\n"
     ]
    }
   ],
   "source": [
    "for doc, score in docs:  #Search content\n",
    "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a8919",
   "metadata": {},
   "source": [
    "##### D1. Setup retriever object for downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7dc47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f3cc706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity_score_threshold\", \n",
    "                            search_kwargs={\"score_threshold\": 0.3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822191e1",
   "metadata": {},
   "source": [
    "##### E. Setup my OpenAI Chat LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af227af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600bfcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6919c07f",
   "metadata": {},
   "source": [
    "##### F. Setup conversational memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccc03a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d4de5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4889d38",
   "metadata": {},
   "source": [
    "##### G1. Helper tools to add to the LLM Chat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d3ad0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad404cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math_model = LLMMathChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d53e3799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 63'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_math_model.run(question='What is 3 squared multiplied by 7?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f81d5d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3**2 * 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0aaf91",
   "metadata": {},
   "source": [
    "##### G2. Specialised teaching agent with sources using retriever object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "422c08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_qa_with_sources_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7088925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_system_template = \"\"\"\n",
    "You are a specialized teacher chatbot with expertise in causal inference using Python. \n",
    "Your primary role is to guide students through interactive lessons, hands-on exercises, and provide thoughtful insights. \n",
    "You will help students understand the underlying principles, methodologies, and practical applications of causal inference.\n",
    "\n",
    "Your responses should be clear, concise, and tailored to the students' level of understanding, encouraging \n",
    "them to think critically and engage with the material. \n",
    "Encourage questions and provide examples where necessary to illustrate complex ideas.\n",
    "\n",
    "When explaining concepts, refer to the internal documents by citing page numbers or section headers as provided from the \n",
    "vector store. Do not reference any external links or sources outside the provided internal documents. \n",
    "Ensure you added page numbers at the end of your response without exception? Citing content is a must.\n",
    "\n",
    "Page: {page}\\nSource: {source}\n",
    "\"\"\"\n",
    "\n",
    "teacher_human_template = 'As a teacher of this book answer this question. Be verbose in your response.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3ebdd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_llm = create_qa_with_sources_chain(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0afb460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_llm_chain = StuffDocumentsChain(\n",
    "    llm_chain=teacher_llm,\n",
    "    document_variable_name=\"context\",\n",
    "    document_prompt=ChatPromptTemplate.from_messages([teacher_system_template,teacher_human_template])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c9b74663",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_chain= RetrievalQA(retriever=retriever, combine_documents_chain=teacher_llm_chain,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e0b2611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is OLS sometimes not an indicator in casuality and how can I use OLS coeficients to determine causality?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "514272d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"answer\": \"OLS (Ordinary Least Squares) is sometimes not an indicator of causality in causal inference. While OLS can provide estimates of the relationship between variables, it does not establish a causal relationship between them. This is because OLS assumes that there are no omitted variables, no measurement error, and no endogeneity issues. However, in real-world scenarios, these assumptions are often violated.\\\\n\\\\nTo determine causality using OLS coefficients, you can follow a few steps:\\\\n\\\\n1. Specify a causal model: Clearly define the causal relationship you want to investigate. Identify the dependent variable (outcome) and the independent variable (treatment/exposure).\\\\n\\\\n2. Control for confounding variables: Identify potential confounding variables that may affect both the independent variable and the dependent variable. Include these variables as control variables in your regression model to reduce the bias caused by confounding.\\\\n\\\\n3. Assess the significance and direction of the coefficient: After running the OLS regression, examine the coefficient of the independent variable. If the coefficient is statistically significant and has the expected sign (positive or negative), it suggests a potential causal relationship.\\\\n\\\\n4. Consider alternative explanations: Even if the coefficient is statistically significant, it is essential to consider alternative explanations and potential omitted variables that may influence the relationship.\\\\n\\\\n5. Conduct robustness checks: Perform sensitivity analyses and robustness checks to test the stability of the results. This can involve using different model specifications, alternative control variables, or different estimation techniques.\\\\n\\\\nIt is important to note that while OLS coefficients can provide valuable insights, they do not establish causality on their own. Causal inference requires careful consideration of the underlying assumptions, study design, and potential sources of bias. For a more comprehensive understanding of causal inference, please refer to page 116 of the book \\'Causal Inference in Python\\'.\",\\n  \"sources\": [\"data/Causal_Inference_in_Python.pdf\"]\\n}'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_chain.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b385e6d6",
   "metadata": {},
   "source": [
    "##### G3. Reasoning teaching agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cc7cd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_system_template = \"\"\"\n",
    "You are an autoregressive language model that has been fine-tuned with instruction-tuning and RLHF. \n",
    "You carefully provide accurate, factual, thoughtful, nuanced answers, and are brilliant at reasoning. \n",
    "If you think there might not be a correct answer, you say so.\n",
    "\n",
    "Since you are autoregressive, each token you produce is another opportunity to use computation, \n",
    "therefore you always spend a few sentences explaining background context, assumptions, and step-by-step thinking \n",
    "BEFORE you try to answer a question.\n",
    "\n",
    "Your users are experts in AI and ethics, so they already know you're a language model and your capabilities and limitations, \n",
    "so don't remind them of that. They're familiar with ethical issues in general so you don't need to remind them about \n",
    "those either.\n",
    "\n",
    "Be verbose in your answers, and do provide details and examples where it might help the explanation. \n",
    "When showing Python code, minimise vertical space, and do not include comments or docstrings; you do not need to follow PEP8, \n",
    "since your users' organizations do not do so.\n",
    "\n",
    "Do not reference any external links or sources outside the provided internal documents. \n",
    "Ensure you added page numbers at the end of your response without exception? Citing content is a must.\n",
    "\n",
    "Page: {page}\\nSource: {source}\n",
    "\"\"\"\n",
    "\n",
    "reasoning_human_template = 'As a teacher of this book answer this question'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "195dd925",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm = create_qa_with_sources_chain(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0d22b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_llm_chain = StuffDocumentsChain(\n",
    "    llm_chain=reasoning_llm,\n",
    "    document_variable_name=\"context\",\n",
    "    document_prompt=ChatPromptTemplate.from_messages([reasoning_system_template,reasoning_human_template])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6423c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_chain= RetrievalQA(retriever=retriever, combine_documents_chain=reasoning_llm_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f9dd4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Why should I read this book?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d0e78972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"answer\": \"There are several reasons why you should read this book. Firstly, this book provides a comprehensive introduction to causal inference in Python. It covers various concepts, methods, and techniques that are essential for understanding and conducting causal analysis. By reading this book, you will gain a solid foundation in causal inference and learn how to apply these techniques in real-world scenarios.\\\\n\\\\nSecondly, this book offers a practical approach to causal inference. It not only explains the theoretical concepts but also provides step-by-step instructions and code examples in Python. This allows you to implement and experiment with different causal inference methods using real data.\\\\n\\\\nThirdly, this book is written in a clear and accessible manner. The authors have made an effort to explain complex concepts in a way that is easy to understand, even for readers who are new to the field of causal inference. The book also includes numerous illustrations, diagrams, and examples to enhance the learning experience.\\\\n\\\\nLastly, this book is highly relevant for researchers, data scientists, and practitioners in various fields. Causal inference is a fundamental aspect of data analysis and decision-making, and understanding causal relationships is crucial for making informed decisions. By reading this book, you will acquire the knowledge and skills necessary to conduct rigorous causal analysis and contribute to advancements in your respective field.\\\\n\\\\nOverall, reading this book will provide you with a solid understanding of causal inference, practical skills in Python programming for causal analysis, and the ability to apply causal inference techniques to real-world problems. It is a valuable resource for anyone interested in causal inference and its applications.\",\\n  \"sources\": [\"data/Causal_Inference_in_Python.pdf\"]\\n}'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6091cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Who wrote this book and are they any good?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fd4a5099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"answer\": \"The book \\'Causal Inference in Python\\' was written by Amit Sharma. Amit Sharma is a data scientist and a researcher in causal inference and machine learning. He has extensive experience in applying causal inference methods to real-world problems. As for whether he is any good, it is subjective and depends on individual opinions. However, considering his expertise in the field and the positive reception of the book, it can be inferred that he is knowledgeable and skilled in the subject matter.\",\\n  \"sources\": [\"Causal_Inference_in_Python.pdf (page 20)\"]\\n}'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "46a642f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'tell me about Amit Sharma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "777523ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"answer\": \"Amit Sharma is a renowned author and data scientist. He has made significant contributions to the field of causal inference and has authored the book \\'Causal Inference in Python\\'. In this book, Sharma provides a comprehensive guide to understanding and applying causal inference techniques using Python programming language.\\\\n\\\\nSharma\\'s expertise lies in the intersection of statistics, machine learning, and causal inference. He has a deep understanding of the challenges and nuances involved in drawing causal conclusions from observational data.\\\\n\\\\nIn \\'Causal Inference in Python\\', Sharma covers various topics related to causal inference, including potential outcomes framework, causal graphs, identification strategies, and estimation methods. He provides clear explanations of these concepts and demonstrates their implementation using Python code examples.\\\\n\\\\nSharma\\'s book is highly regarded in the data science community for its practical approach to causal inference. It equips readers with the necessary tools and knowledge to tackle real-world causal inference problems.\\\\n\\\\n(Page 12, Causal_Inference_in_Python.pdf)\",\\n  \"sources\": [\"data/Causal_Inference_in_Python.pdf\"]\\n}'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62ec7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a5e748b",
   "metadata": {},
   "source": [
    "##### H. Build an Agent with the above three chains and include memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a8654c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "43f06bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [Tool(\n",
    "    name=\"Math model\", \n",
    "    func=llm_math_model.run,\n",
    "    description=\"For any math or computational tasks\"),\n",
    "        \n",
    "        Tool(\n",
    "    name=\"Teacher_chain\", \n",
    "    func=teacher_chain.run,\n",
    "    description=\"For any questions that require a teacher to explain something\"),\n",
    "       \n",
    "        Tool(\n",
    "    name=\"Reasoning_chain\", \n",
    "    func=reasoning_llm.run,\n",
    "    description=\"For any questions that require reasoning skills\"),\n",
    "       \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "385f01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         memory=memory,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79582815",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = agent_chain.run(input=query_str)\n",
    "except ValueError as e:\n",
    "    response = str(e)\n",
    "    if not response.startswith(\"Could not parse LLM output: `\"):\n",
    "        raise e\n",
    "    response = response.removeprefix(\"Could not parse LLM output: `\").removesuffix(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "162817b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: `I need more information to answer this question.`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[248], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is the book about?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:480\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    476\u001b[0m         _output_key\n\u001b[0;32m    477\u001b[0m     ]\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    481\u001b[0m         _output_key\n\u001b[0;32m    482\u001b[0m     ]\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    283\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    284\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    286\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    270\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    271\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    279\u001b[0m     )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:1036\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1036\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1045\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1046\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:844\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    842\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m--> 844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    845\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:833\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    830\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 833\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m    834\u001b[0m         intermediate_steps,\n\u001b[0;32m    835\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m    837\u001b[0m     )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:457\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    456\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:52\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AgentFinish(\n\u001b[0;32m     48\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: text\u001b[38;5;241m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()}, text\n\u001b[0;32m     49\u001b[0m     )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[0;32m     55\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m     56\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[0;32m     60\u001b[0m ):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     63\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE,\n\u001b[0;32m     64\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m     65\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     66\u001b[0m     )\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `I need more information to answer this question.`"
     ]
    }
   ],
   "source": [
    "agent.run(input='What is the book about?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f0b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
